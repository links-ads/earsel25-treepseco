# General
batch_size: 4
num_workers: 4
max_epochs: 800
accelerator: "gpu"
devices: 1
# val_check_interval: 1.0 # this for in epoch val, or when using steps
check_val_every_n_epoch: 7 #! this for val every n epoch
# Optimizer and Scheduler
learning_rate: 1e-5 #! check this
weight_decay: 0.0
scheduler_patience: 4
early_stopping_patience: 20
# Lightning Tensorboard name
experiment_name: "sam_point_decoder_finetune"
version: ""
# Lightning Trainer parameters for efficient training
precision: 16-mixed
# gradient_clip_val: 1.0
# accumulate_grad_batches: 1
# Save checkpoint weight prefix
checkpoint_weight_prefix: "point_decoder."
checkpoint_exclude_prefixes:
  - sam
# Visualization and logging
log_every_n_steps: 10
viz_train_images_every_n_epochs: 5
viz_n_train_images: 5
viz_val_images_every_n_epochs: 1
viz_n_val_images: 10
visualize_random_images: true
loss_type: mse #ssim